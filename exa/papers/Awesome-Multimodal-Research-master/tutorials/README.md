# Tutorials
[Multi-modal Information Extraction from Text, Semi-structured, and Tabular Data on the Web (Cutting-edge)](https://sites.google.com/view/acl-2020-multi-modal-ie), ACL 2020

[Achieving Common Ground in Multi-modal Dialogue (Cutting-edge)](https://github.com/malihealikhani/Grounding_in_Dialogue), ACL 2020

[Recent Advances in Vision-and-Language Research](https://rohit497.github.io/Recent-Advances-in-Vision-and-Language-Research/), CVPR 2020

[Neuro-Symbolic Visual Reasoning and Program Synthesis](http://nscv.csail.mit.edu/), CVPR 2020

[Large Scale Holistic Video Understanding](https://holistic-video-understanding.github.io/tutorials/cvpr2020.html), CVPR 2020

[A Comprehensive Tutorial on Video Modeling](https://cvpr20-video.mxnet.io/), CVPR 2020

[Connecting Language and Vision to Actions](https://lvatutorial.github.io/), ACL 2018

[Machine Learning for Clinicians: Advances for Multi-Modal Health Data](https://www.michaelchughes.com/mlhc2018_tutorial.html), MLHC 2018

[Multimodal Machine Learning](https://sites.google.com/site/multiml2016cvpr/), ACL 2017, CVPR 2016, ICMI 2016

[Vision and Language: Bridging Vision and Language with Deep Learning](https://www.microsoft.com/en-us/research/publication/vision-language-bridging-vision-language-deep-learning/), ICIP 2017
